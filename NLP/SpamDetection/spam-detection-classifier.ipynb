{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"spam.csv\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"v1\",\"v2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.v2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.v2\n",
    "y = data.v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings that you use for count vectorizer will go here\n",
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True)\n",
    " \n",
    "# just send in all your docs here\n",
    "tfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x8672 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 73916 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first vector out (for the first document)\n",
    "first_vector_tfidfvectorizer=tfidf_vectorizer_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>jurong</th>\n",
       "      <td>0.326425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amore</th>\n",
       "      <td>0.326425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buffet</th>\n",
       "      <td>0.311608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bugis</th>\n",
       "      <td>0.275765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cine</th>\n",
       "      <td>0.275765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la</th>\n",
       "      <td>0.275765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point</th>\n",
       "      <td>0.255315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crazy</th>\n",
       "      <td>0.252794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available</th>\n",
       "      <td>0.244155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>until</th>\n",
       "      <td>0.229985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>0.220801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wat</th>\n",
       "      <td>0.182387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>0.180318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>only</th>\n",
       "      <td>0.156180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>there</th>\n",
       "      <td>0.155664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got</th>\n",
       "      <td>0.153189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>0.148130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.107204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personality</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perspective</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person2die</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persolvo</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personal</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persian</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persevered</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>persons</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personally</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perpetual</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enc</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empty</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employer</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employee</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emily</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emigrated</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emerging</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emergency</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emc1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embassy</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarrassed</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarassing</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarassed</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emailed</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>em</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elvis</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elsewhere</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>else</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ello</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elliot</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eleven</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elephant</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elections</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>election</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eldest</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ûówell</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8672 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tfidf\n",
       "jurong       0.326425\n",
       "amore        0.326425\n",
       "buffet       0.311608\n",
       "bugis        0.275765\n",
       "cine         0.275765\n",
       "la           0.275765\n",
       "point        0.255315\n",
       "crazy        0.252794\n",
       "available    0.244155\n",
       "until        0.229985\n",
       "world        0.220801\n",
       "wat          0.182387\n",
       "great        0.180318\n",
       "only         0.156180\n",
       "there        0.155664\n",
       "got          0.153189\n",
       "go           0.148130\n",
       "in           0.107204\n",
       "personality  0.000000\n",
       "person       0.000000\n",
       "perspective  0.000000\n",
       "person2die   0.000000\n",
       "persolvo     0.000000\n",
       "personal     0.000000\n",
       "persian      0.000000\n",
       "persevered   0.000000\n",
       "persons      0.000000\n",
       "personally   0.000000\n",
       "00           0.000000\n",
       "perpetual    0.000000\n",
       "...               ...\n",
       "enc          0.000000\n",
       "en           0.000000\n",
       "empty        0.000000\n",
       "employer     0.000000\n",
       "employee     0.000000\n",
       "emotion      0.000000\n",
       "emily        0.000000\n",
       "emigrated    0.000000\n",
       "emerging     0.000000\n",
       "emergency    0.000000\n",
       "emc1         0.000000\n",
       "embassy      0.000000\n",
       "embarrassed  0.000000\n",
       "embarassing  0.000000\n",
       "embarassed   0.000000\n",
       "emailed      0.000000\n",
       "email        0.000000\n",
       "em           0.000000\n",
       "elvis        0.000000\n",
       "elsewhere    0.000000\n",
       "else         0.000000\n",
       "ello         0.000000\n",
       "elliot       0.000000\n",
       "eleven       0.000000\n",
       "elephant     0.000000\n",
       "electricity  0.000000\n",
       "elections    0.000000\n",
       "election     0.000000\n",
       "eldest       0.000000\n",
       "ûówell       0.000000\n",
       "\n",
       "[8672 rows x 1 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# place tf-idf values in a pandas data frame\n",
    "df = pd.DataFrame(first_vector_tfidfvectorizer.T.todense(), index=tfidf_vectorizer.get_feature_names(), columns=[\"tfidf\"])\n",
    "df.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings that you use for count vectorizer will go here\n",
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True)\n",
    " \n",
    "# just send in all your docs here\n",
    "X_train=tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3343x6663 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 44363 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9569313593539704"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use multinomial naive bayes\n",
    "model = MultinomialNB()        spam       0.99      0.78      0.87       299\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      1.00      0.98      1930\n",
      "        spam       1.00      0.68      0.81       299\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      2229\n",
      "   macro avg       0.98      0.84      0.89      2229\n",
      "weighted avg       0.96      0.96      0.95      2229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9672498878420817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.99      0.98      1930\n",
      "        spam       0.96      0.79      0.87       299\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      2229\n",
      "   macro avg       0.96      0.89      0.92      2229\n",
      "weighted avg       0.97      0.97      0.97      2229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use adaboost\n",
    "adaBoostModel = AdaBoostClassifier()\n",
    "adaBoostModel.fit(X_train,y_train)\n",
    "y_pred = adaBoostModel.predict(X_test)\n",
    "print(adaBoostModel.score(X_test,y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9694930462090624\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98      1930\n",
      "        spam       0.99      0.78      0.87       299\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      2229\n",
      "   macro avg       0.98      0.89      0.93      2229\n",
      "weighted avg       0.97      0.97      0.97      2229\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#use svm\n",
    "randomForestClassifier = RandomForestClassifier()\n",
    "randomForestClassifier.fit(X_train,y_train)\n",
    "y_pred = randomForestClassifier.predict(X_test)\n",
    "print(randomForestClassifier.score(X_test,y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
